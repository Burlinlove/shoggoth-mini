#!/usr/bin/env python3
"""æ¼”ç¤ºå¦‚ä½•åŠ è½½è®­ç»ƒå¥½çš„RLæ¨¡å‹å¹¶åœ¨MuJoCoä¸­æµ‹è¯•"""

import sys
import os
import time
from pathlib import Path
import numpy as np
from stable_baselines3 import PPO
from shoggoth_mini.training.rl.environment import TentacleTargetFollowingEnv
from shoggoth_mini.configs.rl_training import RLEnvironmentConfig

def find_latest_model():
    """æŸ¥æ‰¾æœ€æ–°è®­ç»ƒçš„æ¨¡å‹"""
    results_dir = Path("results")
    if not results_dir.exists():
        return None
    
    # æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒè¿è¡Œ
    run_dirs = [d for d in results_dir.iterdir() if d.is_dir() and d.name.startswith("ppo_tentacle_")]
    if not run_dirs:
        return None
    
    latest_run = max(run_dirs, key=lambda d: d.name)
    
    # ä¼˜å…ˆé€‰æ‹©æœ€ä½³æ¨¡å‹ï¼Œå…¶æ¬¡æ˜¯æœ€ç»ˆæ¨¡å‹
    best_model_path = latest_run / "models" / "best_model.zip"
    final_model_path = latest_run / "models" / "final_model.zip"
    
    if best_model_path.exists():
        return best_model_path
    elif final_model_path.exists():
        return final_model_path
    else:
        return None

def test_trained_model(model_path: str = None, num_episodes: int = 5, step_delay: float = 0.05):
    """æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹"""
    
    # å¦‚æœæ²¡æœ‰æä¾›æ¨¡å‹è·¯å¾„ï¼Œè‡ªåŠ¨æŸ¥æ‰¾
    if model_path is None:
        model_path = find_latest_model()
        if model_path is None:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼")
            print("   è¯·å…ˆè¿è¡Œè®­ç»ƒ: python -m shoggoth_mini.training.rl.training train")
            return
        print(f"ğŸ” è‡ªåŠ¨æ‰¾åˆ°æ¨¡å‹: {model_path}")
    else:
        model_path = Path(model_path)
        if not model_path.exists():
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return
    
    print(f"ğŸš€ åŠ è½½æ¨¡å‹: {model_path}")
    
    try:
        # åŠ è½½è®­ç»ƒå¥½çš„PPOæ¨¡å‹
        model = PPO.load(str(model_path))
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        
        # åˆ›å»ºæµ‹è¯•ç¯å¢ƒï¼ˆå¸¦å¯è§†åŒ–ï¼‰
        config = RLEnvironmentConfig()
        env = TentacleTargetFollowingEnv(config=config, render_mode="human")
        print("âœ… MuJoCoç¯å¢ƒå·²åˆ›å»º!")
        
        print(f"\nğŸ¬ å¼€å§‹æµ‹è¯•è®­ç»ƒå¥½çš„æ™ºèƒ½ä½“...")
        print(f"   - æµ‹è¯•å›åˆæ•°: {num_episodes}")
        print(f"   - æ­¥éª¤å»¶è¿Ÿ: {step_delay:.3f}ç§’ (è®©åŠ¨ä½œæ›´å®¹æ˜“è§‚å¯Ÿ)")
        print(f"   - è§‚å¯Ÿæ™ºèƒ½ä½“å¦‚ä½•æ§åˆ¶è§¦æ‰‹è¿½è¸ªç›®æ ‡")
        print(f"   - æŒ‰ESCå¯æå‰é€€å‡º")
        
        # æ€§èƒ½ç»Ÿè®¡
        episode_rewards = []
        episode_lengths = []
        success_episodes = 0
        success_threshold = 0.05  # 5cmå†…ç®—æˆåŠŸ
        
        for episode in range(num_episodes):
            print(f"\nğŸ“Š ç¬¬ {episode + 1}/{num_episodes} å›åˆ")
            
            obs, info = env.reset()
            episode_reward = 0
            episode_length = 0
            
            while True:
                # æ™ºèƒ½ä½“å†³ç­– (ç¡®å®šæ€§åŠ¨ä½œ)
                action, _states = model.predict(obs, deterministic=True)
                
                # ç¯å¢ƒæ­¥è¿›
                obs, reward, terminated, truncated, info = env.step(action)
                
                # æ·»åŠ å»¶è¿Ÿè®©æ­¥éª¤æ›´å®¹æ˜“è§‚å¯Ÿ
                time.sleep(step_delay)
                
                episode_reward += reward
                episode_length += 1
                
                # æ˜¾ç¤ºå½“å‰çŠ¶æ€
                if episode_length % 20 == 0:  # æ¯20æ­¥æ˜¾ç¤ºä¸€æ¬¡
                    tip_pos = info.get('tip_position', [0, 0, 0])
                    target_pos = info.get('target_position', [0, 0, 0])
                    distance = info.get('distance', 0)
                    print(f"     æ­¥éª¤ {episode_length}: è·ç¦»={distance:.3f}m, å¥–åŠ±={reward:.3f}")
                
                # æ£€æŸ¥æ˜¯å¦ç»“æŸ
                if terminated or truncated:
                    break
            
            # è®°å½•ç»Ÿè®¡ä¿¡æ¯
            final_distance = info.get('distance', float('inf'))
            episode_rewards.append(episode_reward)
            episode_lengths.append(episode_length)
            
            if final_distance < success_threshold:
                success_episodes += 1
                success_status = "âœ… æˆåŠŸ"
            else:
                success_status = "âŒ å¤±è´¥"
            
            print(f"     å›åˆç»“æœ: å¥–åŠ±={episode_reward:.2f}, æ­¥æ•°={episode_length}, æœ€ç»ˆè·ç¦»={final_distance:.3f}m {success_status}")
        
        env.close()
        
        # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
        print(f"\nğŸ“ˆ æµ‹è¯•å®Œæˆ! æ•´ä½“è¡¨ç°:")
        print(f"   - å¹³å‡å¥–åŠ±: {np.mean(episode_rewards):.2f} Â± {np.std(episode_rewards):.2f}")
        print(f"   - å¹³å‡æ­¥æ•°: {np.mean(episode_lengths):.1f} Â± {np.std(episode_lengths):.1f}")
        print(f"   - æˆåŠŸç‡: {success_episodes}/{num_episodes} ({100*success_episodes/num_episodes:.1f}%)")
        print(f"   - å¹³å‡æœ€ç»ˆè·ç¦»: {np.mean([info.get('distance', 0) for info in [{}]]):.3f}m")
        
        print(f"\nğŸŠ æ¨¡å‹æµ‹è¯•å®Œæˆ! æ™ºèƒ½ä½“è¡¨ç°:", end="")
        if success_episodes >= num_episodes * 0.8:
            print("ä¼˜ç§€! ğŸ†")
        elif success_episodes >= num_episodes * 0.6:
            print("è‰¯å¥½! ğŸ‘")
        elif success_episodes >= num_episodes * 0.4:
            print("è¿˜è¡Œ! ğŸ¤”")
        else:
            print("éœ€è¦æ›´å¤šè®­ç»ƒ! ğŸ’ª")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§  è®­ç»ƒå¥½çš„RLæ¨¡å‹MuJoCoæµ‹è¯•å™¨")
    print("=" * 50)
    
    if len(sys.argv) > 1:
        model_path = sys.argv[1]
        print(f"ğŸ“ æŒ‡å®šæ¨¡å‹è·¯å¾„: {model_path}")
    else:
        model_path = None
        print("ğŸ” è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°è®­ç»ƒçš„æ¨¡å‹...")
    
    num_episodes = int(sys.argv[2]) if len(sys.argv) > 2 else 5
    step_delay = float(sys.argv[3]) if len(sys.argv) > 3 else 0.05
    
    print(f"ğŸ® æµ‹è¯•å‚æ•°:")
    print(f"   - å›åˆæ•°: {num_episodes}")
    print(f"   - æ­¥éª¤å»¶è¿Ÿ: {step_delay:.3f}ç§’")
    
    test_trained_model(model_path, num_episodes, step_delay)

if __name__ == "__main__":
    main()
